{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "410c1743-9fa0-4b2a-b503-6afe70711041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please set env variable SPARK_VERSION\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from test_methods.ipynb\n",
      "Creating Spark Session\n",
      "test constraint check set 1\n",
      "Reading s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2002.json Data\n",
      "Python Callback server started!\n",
      "[Row(constraint_status='Success')]\n",
      "Passed - \tSizeConstraint(Size(None)) passed\n",
      "*********************************************************\n",
      "test constraint check set 2\n",
      "Reading s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2003.json Data\n",
      "[Row(constraint_status='Success')]\n",
      "Passed - \tSizeConstraint(Size(None)) passed\n",
      "*********************************************************\n",
      "test constraint check set 3\n",
      "Reading s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2004.json Data\n",
      "[Row(constraint_status='Success')]\n",
      "Passed - \tSizeConstraint(Size(None)) passed\n",
      "*********************************************************\n",
      "test constraint check set 4\n",
      "Reading s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2005.json Data\n",
      "[Row(constraint_status='Success')]\n",
      "Passed - \tSizeConstraint(Size(None)) passed\n",
      "*********************************************************\n",
      "test constraint check set 5\n",
      "Reading s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2006.json Data\n",
      "[Row(constraint_status='Success')]\n",
      "Passed - \tSizeConstraint(Size(None)) passed\n",
      "*********************************************************\n",
      "test constraint check set 6\n",
      "Reading s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2007.json Data\n",
      "[Row(constraint_status='Success')]\n",
      "Passed - \tSizeConstraint(Size(None)) passed\n",
      "*********************************************************\n",
      "test constraint check set 7\n",
      "Reading s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2008.json Data\n",
      "[Row(constraint_status='Success')]\n",
      "Passed - \tSizeConstraint(Size(None)) passed\n",
      "*********************************************************\n",
      "test constraint check set 8\n",
      "Reading s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2009.json Data\n",
      "[Row(constraint_status='Success')]\n",
      "Passed - \tSizeConstraint(Size(None)) passed\n",
      "*********************************************************\n",
      "test constraint check set 9\n",
      "Reading s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2010.json Data\n",
      "[Row(constraint_status='Success')]\n",
      "Passed - \tSizeConstraint(Size(None)) passed\n",
      "*********************************************************\n",
      "test constraint check set 10\n",
      "Reading s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2011.json Data\n",
      "[Row(constraint_status='Success')]\n",
      "Passed - \tSizeConstraint(Size(None)) passed\n",
      "*********************************************************\n",
      "test constraint check set 11\n",
      "Reading s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2012.json Data\n",
      "[Row(constraint_status='Success')]\n",
      "Passed - \tSizeConstraint(Size(None)) passed\n",
      "*********************************************************\n",
      "test constraint check set 12\n",
      "Reading s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2013.json Data\n",
      "[Row(constraint_status='Success')]\n",
      "Passed - \tSizeConstraint(Size(None)) passed\n",
      "*********************************************************\n",
      "test constraint check set 13\n",
      "Reading s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2014.json Data\n",
      "[Row(constraint_status='Success')]\n",
      "Passed - \tSizeConstraint(Size(None)) passed\n",
      "*********************************************************\n",
      "test constraint check set 14\n",
      "Reading s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2015.json Data\n",
      "[Row(constraint_status='Success')]\n",
      "Passed - \tSizeConstraint(Size(None)) passed\n",
      "*********************************************************\n",
      "test constraint check set 15\n",
      "Reading s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2016.json Data\n",
      "[Row(constraint_status='Success')]\n",
      "Passed - \tSizeConstraint(Size(None)) passed\n",
      "*********************************************************\n",
      "test constraint check set 16\n",
      "Reading s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2017.json Data\n",
      "[Row(constraint_status='Success')]\n",
      "Passed - \tSizeConstraint(Size(None)) passed\n",
      "*********************************************************\n",
      "test constraint check set 17\n",
      "Reading s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2018.json Data\n",
      "[Row(constraint_status='Success')]\n",
      "Passed - \tSizeConstraint(Size(None)) passed\n",
      "*********************************************************\n",
      "test constraint check set 18\n",
      "Reading s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2019.json Data\n",
      "[Row(constraint_status='Success')]\n",
      "Passed - \tSizeConstraint(Size(None)) passed\n",
      "*********************************************************\n",
      "test constraint check set 19\n",
      "Reading s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2020.json Data\n",
      "[Row(constraint_status='Success')]\n",
      "Passed - \tSizeConstraint(Size(None)) passed\n",
      "*********************************************************\n",
      "test constraint check set 20\n",
      "Reading s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2021.json Data\n",
      "[Row(constraint_status='Success')]\n",
      "Passed - \tSizeConstraint(Size(None)) passed\n",
      "*********************************************************\n",
      "test constraint check set 21\n",
      "Reading s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2022.json Data\n",
      "[Row(constraint_status='Success')]\n",
      "Passed - \tSizeConstraint(Size(None)) passed\n",
      "*********************************************************\n",
      "test constraint check set 22\n",
      "Reading s3://tahoeqa-raw-data/nvd/nvdcve-1.1-recent.json Data\n",
      "[Row(constraint_status='Success')]\n",
      "Passed - \tSizeConstraint(Size(None)) passed\n",
      "*********************************************************\n",
      "*********************************************************\n",
      "*********************************************************\n",
      "Total Passed Tests = 0\n",
      "Total Failed Tests = 0\n",
      "Total Tests = 0\n",
      "*********************************************************\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import pydeequ\n",
    "from pydeequ import Check, CheckLevel, AnalysisRunner\n",
    "from pydeequ.analyzers import *\n",
    "from pydeequ.suggestions import *\n",
    "from pydeequ.repository import FileSystemMetricsRepository, ResultKey\n",
    "from pydeequ.verification import VerificationSuite, VerificationResult\n",
    "from pytest_check import check_func\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.functions import col\n",
    "import time\n",
    "import pytest\n",
    "import import_ipynb\n",
    "from test_methods import *\n",
    "\n",
    "\n",
    "#Set Up\n",
    "spark = create_session()\n",
    "\n",
    "# Generate Suggestions\n",
    "# generate_suggestions(json_files)\n",
    "# Analyze Data\n",
    "# analyze_file(raw_files)\n",
    "# Constraint Validation\n",
    "# check_constraints(json_files)\n",
    "check = Check(spark, CheckLevel.Warning, \"NVD Intrim json Data Check\")\n",
    "\n",
    "# tc 1 *********************************************************\n",
    "# CVE_data_timestamp: string (nullable = true)\n",
    "#  |-- CVE_data_type: string (nullable = true)\n",
    "#  |-- CVE_data_version: string (nullable = true)\n",
    "print(\"test constraint check set 1\")\n",
    "print(\"Reading \" + 's3://tahoeqa-raw-data/nvd/nvdcve-1.1-2002.json' + \" Data\")\n",
    "df = spark.read.json('s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2002.json')\n",
    "checkResult = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check\n",
    "#         .isComplete(\"CVE_data_version\")  \\\n",
    "#         .isUnique(\"CVE_data_version\")  \\\n",
    "#         .isNonNegative(\"CVE_data_version\") \\\n",
    "#         .isComplete(\"CVE_data_type\")  \\\n",
    "#         .isUnique(\"CVE_data_type\")  \\\n",
    "#         .isNonNegative(\"CVE_data_type\") \\\n",
    "        .hasSize(lambda x: x >= 10000)) \\\n",
    "    .run()\n",
    "#  |-- CVE_data_format: string (nullable = true)\n",
    "#  |-- CVE_data_numberOfCVEs: string (nullable = true)\n",
    "#  |-- CVE_data_timestamp: string (nullable = true)\n",
    "#  |-- CVE_data_type: string (nullable = true)\n",
    "#  |-- CVE_data_version: string (nullable = true)\n",
    "    \n",
    "    \n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "#checkResult_df.show()\n",
    "print(checkResult_df.select(\"constraint_status\").collect())\n",
    "\n",
    "check_results(checkResult.checkResults)\n",
    "print(\"*********************************************************\")\n",
    "\n",
    "check = Check(spark, CheckLevel.Warning, \"NVD Intrim json Data Check\")\n",
    "\n",
    "\n",
    "# tc 2 *********************************************************\n",
    "print(\"test constraint check set 2\")\n",
    "print(\"Reading \" + 's3://tahoeqa-raw-data/nvd/nvdcve-1.1-2003.json' + \" Data\")\n",
    "df = spark.read.json('s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2003.json')\n",
    "# time.sleep(10)\n",
    "checkResult = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check.hasSize(lambda x: x >= 100000)) \\\n",
    "    .run()\n",
    "# time.sleep(10)\n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "#checkResult_df.show()\n",
    "print(checkResult_df.select(\"constraint_status\").collect())\n",
    "check_results(checkResult.checkResults)\n",
    "print(\"*********************************************************\")\n",
    "\n",
    "check = Check(spark, CheckLevel.Warning, \"NVD Intrim json Data Check\")\n",
    "\n",
    "# tc 3 *********************************************************\n",
    "print(\"test constraint check set 3\")\n",
    "print(\"Reading \" + 's3://tahoeqa-raw-data/nvd/nvdcve-1.1-2004.json' + \" Data\")\n",
    "df = spark.read.json('s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2004.json')\n",
    "# time.sleep(10)\n",
    "checkResult = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check.hasSize(lambda x: x >= 100000)) \\\n",
    "    .run()\n",
    "# time.sleep(10)\n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "#checkResult_df.show()\n",
    "print(checkResult_df.select(\"constraint_status\").collect())\n",
    "check_results(checkResult.checkResults)\n",
    "print(\"*********************************************************\")\n",
    "\n",
    "check = Check(spark, CheckLevel.Warning, \"NVD Intrim json Data Check\")\n",
    "\n",
    "\n",
    "# tc 4 *********************************************************\n",
    "print(\"test constraint check set 4\")\n",
    "print(\"Reading \" + 's3://tahoeqa-raw-data/nvd/nvdcve-1.1-2005.json' + \" Data\")\n",
    "df = spark.read.json('s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2005.json')\n",
    "# time.sleep(10)\n",
    "checkResult = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check.hasSize(lambda x: x >= 100000)) \\\n",
    "    .run()\n",
    "# time.sleep(10)\n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "#checkResult_df.show()\n",
    "print(checkResult_df.select(\"constraint_status\").collect())\n",
    "check_results(checkResult.checkResults)\n",
    "print(\"*********************************************************\")\n",
    "\n",
    "check = Check(spark, CheckLevel.Warning, \"NVD Intrim json Data Check\")\n",
    "\n",
    "\n",
    "# tc 5 *********************************************************\n",
    "print(\"test constraint check set 5\")\n",
    "print(\"Reading \" + 's3://tahoeqa-raw-data/nvd/nvdcve-1.1-2006.json' + \" Data\")\n",
    "df = spark.read.json('s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2006.json')\n",
    "# time.sleep(10)\n",
    "checkResult = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check.hasSize(lambda x: x >= 100000)) \\\n",
    "    .run()\n",
    "# time.sleep(10)\n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "#checkResult_df.show()\n",
    "print(checkResult_df.select(\"constraint_status\").collect())\n",
    "check_results(checkResult.checkResults)\n",
    "print(\"*********************************************************\")\n",
    "\n",
    "check = Check(spark, CheckLevel.Warning, \"NVD Intrim json Data Check\")\n",
    "\n",
    "# tc 6 *********************************************************\n",
    "print(\"test constraint check set 6\")\n",
    "print(\"Reading \" + 's3://tahoeqa-raw-data/nvd/nvdcve-1.1-2007.json' + \" Data\")\n",
    "df = spark.read.json('s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2007.json')\n",
    "# time.sleep(10)\n",
    "checkResult = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check.hasSize(lambda x: x >= 100000)) \\\n",
    "    .run()\n",
    "# time.sleep(10)\n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "#checkResult_df.show()\n",
    "print(checkResult_df.select(\"constraint_status\").collect())\n",
    "check_results(checkResult.checkResults)\n",
    "print(\"*********************************************************\")\n",
    "\n",
    "check = Check(spark, CheckLevel.Warning, \"NVD Intrim json Data Check\")\n",
    "\n",
    "\n",
    "# tc 7 *********************************************************\n",
    "print(\"test constraint check set 7\")\n",
    "print(\"Reading \" + 's3://tahoeqa-raw-data/nvd/nvdcve-1.1-2008.json' + \" Data\")\n",
    "df = spark.read.json('s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2008.json')\n",
    "# time.sleep(10)\n",
    "checkResult = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check.hasSize(lambda x: x >= 100000)) \\\n",
    "    .run()\n",
    "# time.sleep(10)\n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "#checkResult_df.show()\n",
    "print(checkResult_df.select(\"constraint_status\").collect())\n",
    "check_results(checkResult.checkResults)\n",
    "print(\"*********************************************************\")\n",
    "\n",
    "check = Check(spark, CheckLevel.Warning, \"NVD Intrim json Data Check\")\n",
    "\n",
    "\n",
    "# tc 8 *********************************************************\n",
    "print(\"test constraint check set 8\")\n",
    "print(\"Reading \" + 's3://tahoeqa-raw-data/nvd/nvdcve-1.1-2009.json' + \" Data\")\n",
    "df = spark.read.json('s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2009.json')\n",
    "# time.sleep(10)\n",
    "checkResult = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check.hasSize(lambda x: x >= 100000)) \\\n",
    "    .run()\n",
    "# time.sleep(10)\n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "#checkResult_df.show()\n",
    "print(checkResult_df.select(\"constraint_status\").collect())\n",
    "check_results(checkResult.checkResults)\n",
    "print(\"*********************************************************\")\n",
    "\n",
    "check = Check(spark, CheckLevel.Warning, \"NVD Intrim json Data Check\")\n",
    "\n",
    "\n",
    "# tc 9 *********************************************************\n",
    "print(\"test constraint check set 9\")\n",
    "print(\"Reading \" + 's3://tahoeqa-raw-data/nvd/nvdcve-1.1-2010.json' + \" Data\")\n",
    "df = spark.read.json('s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2010.json')\n",
    "# time.sleep(10)\n",
    "checkResult = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check.hasSize(lambda x: x >= 100000)) \\\n",
    "    .run()\n",
    "# time.sleep(10)\n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "#checkResult_df.show()\n",
    "print(checkResult_df.select(\"constraint_status\").collect())\n",
    "check_results(checkResult.checkResults)\n",
    "print(\"*********************************************************\")\n",
    "\n",
    "check = Check(spark, CheckLevel.Warning, \"NVD Intrim json Data Check\")\n",
    "\n",
    "\n",
    "# tc 10 *********************************************************\n",
    "print(\"test constraint check set 10\")\n",
    "print(\"Reading \" + 's3://tahoeqa-raw-data/nvd/nvdcve-1.1-2011.json' + \" Data\")\n",
    "df = spark.read.json('s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2011.json')\n",
    "# time.sleep(10)\n",
    "checkResult = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check.hasSize(lambda x: x >= 100000)) \\\n",
    "    .run()\n",
    "# time.sleep(10)\n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "#checkResult_df.show()\n",
    "print(checkResult_df.select(\"constraint_status\").collect())\n",
    "check_results(checkResult.checkResults)\n",
    "print(\"*********************************************************\")\n",
    "\n",
    "check = Check(spark, CheckLevel.Warning, \"NVD Intrim json Data Check\")\n",
    "\n",
    "# tc 11 *********************************************************\n",
    "print(\"test constraint check set 11\")\n",
    "print(\"Reading \" + 's3://tahoeqa-raw-data/nvd/nvdcve-1.1-2012.json' + \" Data\")\n",
    "df = spark.read.json('s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2012.json')\n",
    "# time.sleep(10)\n",
    "checkResult = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check.hasSize(lambda x: x >= 100000)) \\\n",
    "    .run()\n",
    "# time.sleep(10)\n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "#checkResult_df.show()\n",
    "print(checkResult_df.select(\"constraint_status\").collect())\n",
    "check_results(checkResult.checkResults)\n",
    "print(\"*********************************************************\")\n",
    "\n",
    "check = Check(spark, CheckLevel.Warning, \"NVD Intrim json Data Check\")\n",
    "\n",
    "\n",
    "# tc 12 *********************************************************\n",
    "print(\"test constraint check set 12\")\n",
    "print(\"Reading \" + 's3://tahoeqa-raw-data/nvd/nvdcve-1.1-2013.json' + \" Data\")\n",
    "df = spark.read.json('s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2013.json')\n",
    "# time.sleep(10)\n",
    "checkResult = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check.hasSize(lambda x: x >= 100000)) \\\n",
    "    .run()\n",
    "# time.sleep(10)\n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "#checkResult_df.show()\n",
    "print(checkResult_df.select(\"constraint_status\").collect())\n",
    "check_results(checkResult.checkResults)\n",
    "print(\"*********************************************************\")\n",
    "\n",
    "check = Check(spark, CheckLevel.Warning, \"NVD Intrim json Data Check\")\n",
    "\n",
    "\n",
    "# tc 13 *********************************************************\n",
    "print(\"test constraint check set 13\")\n",
    "print(\"Reading \" + 's3://tahoeqa-raw-data/nvd/nvdcve-1.1-2014.json' + \" Data\")\n",
    "df = spark.read.json('s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2014.json')\n",
    "# time.sleep(10)\n",
    "checkResult = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check.hasSize(lambda x: x >= 100000)) \\\n",
    "    .run()\n",
    "# time.sleep(10)\n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "#checkResult_df.show()\n",
    "print(checkResult_df.select(\"constraint_status\").collect())\n",
    "check_results(checkResult.checkResults)\n",
    "print(\"*********************************************************\")\n",
    "\n",
    "check = Check(spark, CheckLevel.Warning, \"NVD Intrim json Data Check\")\n",
    "\n",
    "\n",
    "# tc 14 *********************************************************\n",
    "print(\"test constraint check set 14\")\n",
    "print(\"Reading \" + 's3://tahoeqa-raw-data/nvd/nvdcve-1.1-2015.json' + \" Data\")\n",
    "df = spark.read.json('s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2015.json')\n",
    "# time.sleep(10)\n",
    "checkResult = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check.hasSize(lambda x: x >= 100000)) \\\n",
    "    .run()\n",
    "# time.sleep(10)\n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "#checkResult_df.show()\n",
    "print(checkResult_df.select(\"constraint_status\").collect())\n",
    "check_results(checkResult.checkResults)\n",
    "print(\"*********************************************************\")\n",
    "\n",
    "check = Check(spark, CheckLevel.Warning, \"NVD Intrim json Data Check\")\n",
    "\n",
    "\n",
    "# tc 15 *********************************************************\n",
    "print(\"test constraint check set 15\")\n",
    "print(\"Reading \" + 's3://tahoeqa-raw-data/nvd/nvdcve-1.1-2016.json' + \" Data\")\n",
    "df = spark.read.json('s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2016.json')\n",
    "# time.sleep(10)\n",
    "checkResult = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check.hasSize(lambda x: x >= 100000)) \\\n",
    "    .run()\n",
    "# time.sleep(10)\n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "#checkResult_df.show()\n",
    "print(checkResult_df.select(\"constraint_status\").collect())\n",
    "check_results(checkResult.checkResults)\n",
    "print(\"*********************************************************\")\n",
    "\n",
    "check = Check(spark, CheckLevel.Warning, \"NVD Intrim json Data Check\")\n",
    "\n",
    "\n",
    "# tc 16 *********************************************************\n",
    "print(\"test constraint check set 16\")\n",
    "print(\"Reading \" + 's3://tahoeqa-raw-data/nvd/nvdcve-1.1-2017.json' + \" Data\")\n",
    "df = spark.read.json('s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2017.json')\n",
    "# time.sleep(10)\n",
    "checkResult = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check.hasSize(lambda x: x >= 100000)) \\\n",
    "    .run()\n",
    "# time.sleep(10)\n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "#checkResult_df.show()\n",
    "print(checkResult_df.select(\"constraint_status\").collect())\n",
    "check_results(checkResult.checkResults)\n",
    "print(\"*********************************************************\")\n",
    "\n",
    "check = Check(spark, CheckLevel.Warning, \"NVD Intrim json Data Check\")\n",
    "\n",
    "\n",
    "# tc 17 *********************************************************\n",
    "print(\"test constraint check set 17\")\n",
    "print(\"Reading \" + 's3://tahoeqa-raw-data/nvd/nvdcve-1.1-2018.json' + \" Data\")\n",
    "df = spark.read.json('s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2018.json')\n",
    "# time.sleep(10)\n",
    "checkResult = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check.hasSize(lambda x: x >= 100000)) \\\n",
    "    .run()\n",
    "# time.sleep(10)\n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "#checkResult_df.show()\n",
    "print(checkResult_df.select(\"constraint_status\").collect())\n",
    "check_results(checkResult.checkResults)\n",
    "print(\"*********************************************************\")\n",
    "\n",
    "check = Check(spark, CheckLevel.Warning, \"NVD Intrim json Data Check\")\n",
    "\n",
    "\n",
    "# tc 18 *********************************************************\n",
    "print(\"test constraint check set 18\")\n",
    "print(\"Reading \" + 's3://tahoeqa-raw-data/nvd/nvdcve-1.1-2019.json' + \" Data\")\n",
    "df = spark.read.json('s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2019.json')\n",
    "# time.sleep(10)\n",
    "checkResult = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check.hasSize(lambda x: x >= 100000)) \\\n",
    "    .run()\n",
    "# time.sleep(10)\n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "#checkResult_df.show()\n",
    "print(checkResult_df.select(\"constraint_status\").collect())\n",
    "check_results(checkResult.checkResults)\n",
    "print(\"*********************************************************\")\n",
    "\n",
    "check = Check(spark, CheckLevel.Warning, \"NVD Intrim json Data Check\")\n",
    "\n",
    "\n",
    "# tc 19 *********************************************************\n",
    "print(\"test constraint check set 19\")\n",
    "print(\"Reading \" + 's3://tahoeqa-raw-data/nvd/nvdcve-1.1-2020.json' + \" Data\")\n",
    "df = spark.read.json('s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2020.json')\n",
    "# time.sleep(10)\n",
    "checkResult = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check.hasSize(lambda x: x >= 100000)) \\\n",
    "    .run()\n",
    "# time.sleep(10)\n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "#checkResult_df.show()\n",
    "print(checkResult_df.select(\"constraint_status\").collect())\n",
    "check_results(checkResult.checkResults)\n",
    "print(\"*********************************************************\")\n",
    "\n",
    "check = Check(spark, CheckLevel.Warning, \"NVD Intrim json Data Check\")\n",
    "\n",
    "\n",
    "# tc 20 *********************************************************\n",
    "print(\"test constraint check set 20\")\n",
    "print(\"Reading \" + 's3://tahoeqa-raw-data/nvd/nvdcve-1.1-2021.json' + \" Data\")\n",
    "df = spark.read.json('s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2021.json')\n",
    "# time.sleep(10)\n",
    "checkResult = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check.hasSize(lambda x: x >= 100000)) \\\n",
    "    .run()\n",
    "# time.sleep(10)\n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "#checkResult_df.show()\n",
    "print(checkResult_df.select(\"constraint_status\").collect())\n",
    "check_results(checkResult.checkResults)\n",
    "print(\"*********************************************************\")\n",
    "\n",
    "check = Check(spark, CheckLevel.Warning, \"NVD Intrim json Data Check\")\n",
    "\n",
    "\n",
    "# tc 21 *********************************************************\n",
    "print(\"test constraint check set 21\")\n",
    "print(\"Reading \" + 's3://tahoeqa-raw-data/nvd/nvdcve-1.1-2022.json' + \" Data\")\n",
    "df = spark.read.json('s3://tahoeqa-raw-data/nvd/nvdcve-1.1-2022.json')\n",
    "# time.sleep(10)\n",
    "checkResult = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check.hasSize(lambda x: x >= 100000)) \\\n",
    "    .run()\n",
    "# time.sleep(10)\n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "#checkResult_df.show()\n",
    "print(checkResult_df.select(\"constraint_status\").collect())\n",
    "check_results(checkResult.checkResults)\n",
    "print(\"*********************************************************\")\n",
    "\n",
    "check = Check(spark, CheckLevel.Warning, \"NVD Intrim json Data Check\")\n",
    "\n",
    "\n",
    "# tc 22 *********************************************************\n",
    "print(\"test constraint check set 22\")\n",
    "print(\"Reading \" + 's3://tahoeqa-raw-data/nvd/nvdcve-1.1-recent.json' + \" Data\")\n",
    "df = spark.read.json('s3://tahoeqa-raw-data/nvd/nvdcve-1.1-recent.json')\n",
    "# time.sleep(10)\n",
    "checkResult = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check.hasSize(lambda x: x >= 10000)) \\\n",
    "    .run()\n",
    "# time.sleep(10)\n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "#checkResult_df.show()\n",
    "print(checkResult_df.select(\"constraint_status\").collect())\n",
    "check_results(checkResult.checkResults)\n",
    "print(\"*********************************************************\")\n",
    "print(\"*********************************************************\")\n",
    "print(\"*********************************************************\")\n",
    "print(\"Total Passed Tests = \" + str(tpass_count))\n",
    "print(\"Total Failed Tests = \" + str(tfail_count))\n",
    "print(\"Total Tests = \" + str(tpass_count + tfail_count))\n",
    "print(\"*********************************************************\")\n",
    "\n",
    "spark.sparkContext._gateway.shutdown_callback_server()\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cf6ae2-3535-4b15-bdd7-3ab318b588f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
